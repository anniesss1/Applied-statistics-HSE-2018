{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 4. Тестрование гипотез:\n",
    "\n",
    "Краткий синопсис:\n",
    "1. Разбор статьи *\"How Many Random Seeds? Statistical Power Analysis in Deep Reinforcement Learning Experiments\"*...\n",
    "2. ...и применение выводов авторов статей на примере задачи сравнения двух моделей для предсказания рака груди (https://archive.ics.uci.edu/ml/datasets/Breast+Cancer)\n",
    "3. Оценка ошибки второго рода оценки $H_0$ - что две модели имеют одну и ту же предсказательную способность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Генерация тестовых выборок с точностями (prediction accuracy) для предсказания рака груди\n",
    "\n",
    "https://arxiv.org/abs/1806.08295"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features from the data set describe characteristics of the cell nuclei and are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. As described in [UCI Machine Learning Repository][1], the attribute informations are:\n",
    "\n",
    "1. ID number\n",
    "2. Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "3 - 32  Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "* a) radius (mean of distances from center to points on the perimeter)\n",
    "* b) texture (standard deviation of gray-scale values)\n",
    "* c) perimeter\n",
    "* d) area\n",
    "* e) smoothness (local variation in radius lengths)\n",
    "* f) compactness (perimeter^2 / area - 1.0)\n",
    "* g) concavity (severity of concave portions of the contour)\n",
    "* h) concave points (number of concave portions of the contour)\n",
    "* i) symmetry\n",
    "* j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "\n",
    "  [1]: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv');\n",
    "\n",
    "print(\"\\n \\t The data frame has {0[0]} rows and {0[1]} columns. \\n\".format(df.shape))\n",
    "df.drop(df.columns[[-1, 0]], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  count how many diagnosis are malignant (M) and how many are benign (B)\n",
    "diagnosis_all = list(df.shape)[0]\n",
    "diagnosis_categories = list(df['diagnosis'].value_counts())\n",
    "\n",
    "print(\"\\n \\t The data has {} diagnosis, {} malignant and {} benign.\".format(diagnosis_all, \n",
    "                                                                            diagnosis_categories[0], \n",
    "                                                                            diagnosis_categories[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fancy fonts\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "# visualising the data\n",
    "features_mean= list(df.columns[1:11])\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df[features_mean].corr(), annot=True, square=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dic = {'M':'red', 'B':'blue'}\n",
    "colors = df['diagnosis'].map(lambda x: color_dic.get(x))\n",
    "\n",
    "sm = pd.scatter_matrix(df[features_mean], c=colors, alpha=0.4, figsize=((15,15)));\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 12\n",
    "plt.figure(figsize=(15,15))\n",
    "for i, feature in enumerate(features_mean):\n",
    "    rows = int(len(features_mean)/2)\n",
    "    \n",
    "    plt.subplot(rows, 2, i+1)\n",
    "    \n",
    "    sns.distplot(df[df['diagnosis']=='M'][feature], bins=bins, color='red', label='M');\n",
    "    sns.distplot(df[df['diagnosis']=='B'][feature], bins=bins, color='blue', label='B');\n",
    "    \n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i, feature in enumerate(features_mean):\n",
    "    rows = int(len(features_mean)/2)\n",
    "    \n",
    "    plt.subplot(rows, 2, i+1)\n",
    "    \n",
    "    sns.boxplot(x='diagnosis', y=feature, data=df, palette=\"Set1\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the models\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "# binarasing the diagnosis\n",
    "diag_map = {'M':1, 'B':0}\n",
    "df['diagnosis'] = df['diagnosis'].map(diag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:,features_mean]\n",
    "y = df.loc[:, 'diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "accuracy_all = []\n",
    "cvs_all = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тренируем два классификатора - Байес и KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The nearest neighbors classifier finds predefined number of training samples closest in distance to the new point, and predict the label from these.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n",
    "print(\"Execution time: {0:.5} seconds \\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Naive Bayes algorithm applies Bayes’ theorem with the assumption of independence between every pair of features.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n",
    "print(\"Execution time: {0:.5} seconds \\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Accuracy: 93.86%, Bayes Accuracy: 94.74% \n",
    "\n",
    "Запомним точность с кроссвалидации на 50 фолдах для сравнения результатов работы двух алгоритмов. Как будто мы усовершенствовали KNN и хотим написать статью о новом методе, и доказываем, что он работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=50)\n",
    "data1=scores # записываем сюда 50 скоров кроссвалидации для KNN классификатора\n",
    "pd.DataFrame(data1).to_csv('data1.csv')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))# видим что дисперсия сильно увеличилась с количеством фолдов\n",
    "print(\"Execution time: {0:.5} seconds \\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "data2=scores # записываем сюда 50 скоров кроссвалидации для Naive Bayes классификатора\n",
    "pd.DataFrame(data2).to_csv('data2.csv')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n",
    "print(\"Execution time: {0:.5} seconds \\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Оценка ошибки второго рода оценки $H_0$\n",
    "\n",
    "![](./stat_errors.png)\n",
    "\n",
    "В статистике различаются два вида ошибок: \n",
    "  * ошибка первого рода -- когда мы отвергаем гипотезу, а она верна;\n",
    "  * ошибка второго рода -- когда мы __не__ отвергаем гипотезу, а она не верна.\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bootstrapped import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем функции для подсчёта бутстрапных статистик:\n",
    "\n",
    "  * `def bootstrap` отвечает за подсчёт интервалов с помощью бутстрапа;\n",
    "  * `bootstrap_ab` производит A/B-тестирование на двух сэмплах с помощью бутстрапа;\n",
    "  * `bootstrap_test` - обёртка над `bootstrap_ab`, которая дополнительно сообщает прошли ли данные тест со значимостью на уровне $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Тест Уелча](http://www.statistics4u.com/fundstat_eng/img/hl_explain_welch_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$t = \\frac{x_{diff}}{\\sqrt{\\frac{s_1^2}{N_1} + \\frac{s_2^2}{N_2}}}$$\n",
    "\n",
    "$$v \\approx \\frac{\\left(\\frac{s_1^2}{N_1} + \\frac{s_2^2}{N_2}\\right)^2}{\\frac{s_1^4}{N_1^2 (N_1 - 1)} + \\frac{s_2^4}{N_2^2 (N_2 - 1)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Реализация теста Уелча\n",
    "https://github.com/flowersteam/rl-difference-testing/blob/master/test_RL_difference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import bootstrap, bootstrap_ab, bootstrap_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * `welch_test` - реализация теста Уельча с помощью `stats.ttest_ind`;\n",
    "  * `compute_beta` - функция для подсчёта вероятности ошибки II рода.\n",
    "  * `empirical_false_pos_rate` - функция для ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import compute_beta, welch_test, empirical_false_pos_rate, plot_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of AB-test with bootstrap\n",
    "\"\"\"\n",
    "    Imagine we own a website and think changing the color of a 'subscribe' button will improve signups. \n",
    "    One method to measure the improvement is to conduct an A/B test where we show 50% of people the old version and 50%\n",
    "    of the people the new version. We can use the bootstrap to understand how much the button color improves responses \n",
    "    and give us the error bars associated with the test - this will give us lower and upper bounds on how good we should \n",
    "    expect the change to be!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mean = 100\n",
    "stdev = 10\n",
    "\n",
    "population = np.random.normal(loc=mean, scale=stdev, size=50000)\n",
    "# take 1k 'samples' from the larger population\n",
    "samples = population[:1000]\n",
    "\n",
    "print(bootstrap(samples, stat_func=mean_))\n",
    "print(bootstrap(samples, stat_func=std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. just random sample. test for N random seeds will fail\n",
    "data1=np.random.random_sample(50)\n",
    "data2=np.random.random_sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance level to be used by both tests\n",
    "alpha = 0.05\n",
    "# Requirement in type-II error\n",
    "beta_requirement = 0.2\n",
    "\n",
    "# define the range of sample size to compute and plot beta\n",
    "sample_size = range(2, 50, 2)\n",
    "\n",
    "# define the effect size epsilon. Here we define epsilon proportionally to smaller average performance\n",
    "if data1.mean() < data2.mean():\n",
    "    m_smaller = data1.mean()\n",
    "else:\n",
    "    m_smaller = data2.mean()\n",
    "epsilon = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]) * m_smaller\n",
    "epsilon = epsilon.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "welch_test(data1, data2, alpha, tail=2)\n",
    "bootstrap_test(data1, data2, alpha)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. random sample with delta\n",
    "data1=np.random.random_sample(100)\n",
    "data2=np.random.random_sample(100)-0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "welch_test(data1, data2, alpha, tail=2)\n",
    "bootstrap_test(data1, data2, alpha)\n",
    "empirical_false_pos_rate(data1, alpha)\n",
    "beta = compute_beta(epsilon, sample_size, alpha, data1, data2, beta_requirement=beta_requirement)\n",
    "plot_beta(beta, epsilon, sample_size, beta_requirement=beta_requirement)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. load generated data from models\n",
    "path_to_data1 = 'data1.csv'\n",
    "path_to_data2 = 'data2.csv'\n",
    "data1 = np.asarray(pd.read_csv(path_to_data1)['0'])\n",
    "data2 = np.asarray(pd.read_csv(path_to_data2)['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "welch_test(data1, data2, alpha, tail=2)\n",
    "bootstrap_test(data1, data2, alpha)\n",
    "empirical_false_pos_rate(data1, alpha)\n",
    "beta = compute_beta(epsilon, sample_size, alpha, data1, data2, beta_requirement=beta_requirement)\n",
    "plot_beta(beta, epsilon, sample_size, beta_requirement=beta_requirement)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличим количество фолдов до 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=100)\n",
    "data1=scores # записываем сюда 100 скоров кроссвалидации для KNN классификатора\n",
    "pd.DataFrame(data1).to_csv('data1.csv')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))# видим что дисперсия сильно увеличилась с количеством фолдов\n",
    "print(\"Execution time: {0:.5} seconds \\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Naive Bayes algorithm applies Bayes’ theorem with the assumption of independence between every pair of features.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=100)\n",
    "data2 =scores # записываем сюда 100 скоров кроссвалидации\n",
    "pd.DataFrame(data2).to_csv('data2.csv')\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n",
    "print(\"Execution time: {0:.5} seconds \\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И потом ещё стохастический градиент можно поробовать до кучи\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf = SGDClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=100)\n",
    "data2=scores # записываем сюда 100 скоров кроссвалидации для Стохастического градиента\n",
    "pd.DataFrame(data2).to_csv('data2.csv')\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"SGD Classifier Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n",
    "print(\"Execution time: %s seconds \\n\" % \"{0:.5}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_to_data1 = 'data1.csv'\n",
    "path_to_data2 = 'data2.csv'\n",
    "data1 = np.asarray(pd.read_csv(path_to_data1)['0'])\n",
    "data2 = np.asarray(pd.read_csv(path_to_data2)['0'])\n",
    "welch_test(data1, data2, alpha, tail=2)\n",
    "bootstrap_test(data1, data2, alpha)\n",
    "empirical_false_pos_rate(data1, alpha)\n",
    "beta = compute_beta(epsilon, sample_size, alpha, data1, data2, beta_requirement=beta_requirement)\n",
    "plot_beta(beta, epsilon, sample_size, beta_requirement=beta_requirement)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=100)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Random Forest Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n",
    "print(\"Execution time: {0:.5} seconds \\n\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
